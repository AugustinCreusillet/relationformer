{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "import torch\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "from medpy.io import load\n",
    "import pyvista\n",
    "import pymeshfix\n",
    "import pyacvd\n",
    "import pymesh\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset_vessel import build_vessel_data\n",
    "from monai.data import DataLoader\n",
    "from torch import nn\n",
    "from skimage.morphology import skeletonize_3d\n",
    "from skimage.measure import marching_cubes_lewiner\n",
    "from scipy.sparse import csr_matrix\n",
    "from models.detr_transformer_3D import build_detr_transformer\n",
    "from models.swin_transformer_3D import build_swin_transformer\n",
    "# from models.matcher import build_matcher\n",
    "from losses import SetCriterion\n",
    "from models import build_model\n",
    "import pyvista\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "# %matplotlib widget\n",
    "import yaml\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import json\n",
    "from models.position_encoding import PositionalEncoding3D\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy import ndimage\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from skimage.morphology import skeletonize_3d\n",
    "from utils import save_input, save_output\n",
    "from utils import Bresenham3D\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class obj:\n",
    "    def __init__(self, dict1):\n",
    "        self.__dict__.update(dict1)\n",
    "        \n",
    "def dict2obj(dict1):\n",
    "    return json.loads(json.dumps(dict1), object_hook=obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/media/Drives/Data/transformer_graph_gen/configs/synth_3D_swin_base_patch4_window7_64_deform_detr.yaml\"\n",
    "\n",
    "with open(config_file) as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "config = dict2obj(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/Drives/Media/vessel_centerline/3D_vessel_data/'\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_vessel_data(config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_graph_collate(batch):\n",
    "    images = torch.cat([item_ for item in batch for item_ in item[0]], 0).contiguous()\n",
    "    points = [item_ for item in batch for item_ in item[1]]\n",
    "    edges = [item_ for item in batch for item_ in item[2]]\n",
    "    return [images, points, edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_dataset_loader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple([y_.to(device) for y_ in x_] for x_ in image_graph_collate(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 torch.Size([6, 1, 64, 64, 64]) torch.Size([37, 3])\n"
     ]
    }
   ],
   "source": [
    "for images, points, edges in mn_dataset_loader:\n",
    "    images = torch.stack(images)\n",
    "    print(len(points), images.shape, points[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "patch = images[i,0,...].cpu().numpy()\n",
    "coord = points[i].cpu().numpy()\n",
    "edge = edges[i].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is good\n"
     ]
    }
   ],
   "source": [
    "# keep only the largest graph (in length or voxel space?)\n",
    "dilated_labels = patch #np.zeros(patch.shape)\n",
    "# dilated_labels[5:-5, 5:-5, 5:-5] = ndimage.morphology.binary_dilation(patch[5:-5, 5:-5, 5:-5], structure=np.ones([3,3,3]))\n",
    "# skel = skeletonize_3d(dilated_labels)\n",
    "image_labeled, n_comp_image = ndimage.label(dilated_labels>0.0, structure=np.ones([3,3,3]))\n",
    "# skel_labeled, n_comp_skel = ndimage.label(skel>0.0, structure=np.ones([3,3,3]))\n",
    "# sizes = ndimage.sum(skel, skel_labeled, range(n_comp_skel + 1))\n",
    "# label_largest_image = np.argmax(sizes)\n",
    "\n",
    "# find largest graph segment in graph and in skeleton and see if they match\n",
    "dist_adj = np.zeros((coord.shape[0], coord.shape[0]))\n",
    "dist_adj[edge[:,0], edge[:,1]] = np.sum((coord[edge[:,0],:]-coord[edge[:,1],:])**2, 1)\n",
    "dist_adj[edge[:,1], edge[:,0]] = np.sum((coord[edge[:,0],:]-coord[edge[:,1],:])**2, 1)\n",
    "\n",
    "graph = csr_matrix(np.triu(dist_adj>0.0))\n",
    "n_comp_graph, graph_labeled = connected_components(csgraph=graph, directed=False, return_labels=True)\n",
    "\n",
    "if n_comp_graph==n_comp_image:\n",
    "    print(\"All is good\")\n",
    "\n",
    "dist = np.zeros(n_comp_graph)\n",
    "for i in range(n_comp_graph):\n",
    "    idx = np.where(graph_labeled==i)[0]\n",
    "    dist[i] = np.sum(np.triu(dist_adj[np.ix_(idx,idx)]))\n",
    "    \n",
    "max_subgraph_label = np.argmax(dist)\n",
    "max_subgraph_coord = np.int32(coord[graph_labeled==max_subgraph_label,:]*(np.array(patch.shape)-1))\n",
    "img_label_max_subgraph = image_labeled[max_subgraph_coord[:,0], max_subgraph_coord[:,1], max_subgraph_coord[:,2]]\n",
    "new_patch = 1.0*(image_labeled==np.median(img_label_max_subgraph[img_label_max_subgraph>0.0]))\n",
    "\n",
    "all_coord = np.int32(coord*(np.array(patch.shape)-1))\n",
    "label = new_patch[all_coord[:,0], all_coord[:,1], all_coord[:,2]]\n",
    "\n",
    "# keep the nodes which lie in the largest compnent and their subgraph\n",
    "keep_graph_label = np.array(np.unique(graph_labeled[label>0]))\n",
    "if keep_graph_label.ndim==0:\n",
    "    final_graph = (graph_labeled==keep_graph_label)\n",
    "else:\n",
    "    final_graph = np.zeros(graph_labeled.shape, dtype=np.bool)\n",
    "    for ind in keep_graph_label:\n",
    "        final_graph += (graph_labeled==ind)\n",
    "new_dist_adj = dist_adj[np.ix_(final_graph,final_graph)]\n",
    "new_coord = coord[final_graph,:]\n",
    "new_edge = np.array(np.where(np.triu(new_dist_adj)>0)).T\n",
    "new_patch = patch*new_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 3)\n",
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "path = ('pre')\n",
    "save_input(path, 1, patch, coord, edge)\n",
    "path = ('post1')\n",
    "save_input(path, 1, new_patch, new_coord, new_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotproduct(v1, v2):\n",
    "    return sum((a*b) for a, b in zip(v1, v2))\n",
    "\n",
    "def length(v):\n",
    "    return math.sqrt(dotproduct(v, v))\n",
    "\n",
    "def angle(v1, v2):\n",
    "    return np.arccos(dotproduct(v1, v2) / (length(v1) * length(v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all: 1 [ 2 10] 141.6501785806879\n",
      "all: 3 [0 7] 135.73562885208713\n",
      "all: 4 [2 8] 172.96645316964396\n",
      "corrected: 4 [2 8] 172.96645316964396\n",
      "all: 1 [ 2 10] 141.6501785806879\n",
      "all: 3 [0 7] 135.73562885208713\n",
      "all: 5 [0 2] 159.64293565946517\n",
      "corrected: 5 [0 2] 159.64293565946517\n",
      "all: 1 [ 2 10] 141.6501785806879\n",
      "all: 3 [0 7] 135.73562885208713\n",
      "all: 6 [0 9] 151.4893583886943\n",
      "corrected: 6 [0 9] 151.4893583886943\n",
      "all: 1 [ 2 10] 141.6501785806879\n",
      "all: 3 [0 7] 135.73562885208713\n"
     ]
    }
   ],
   "source": [
    "start = True\n",
    "node_mask = np.ones(new_coord.shape[0], dtype=np.bool)\n",
    "while start:\n",
    "    degree = (new_dist_adj>0).sum(1)\n",
    "    deg_2 = list(np.where(degree==2)[0])\n",
    "    for n, idx in enumerate(deg_2):\n",
    "        deg_2_neighbor = np.where(new_dist_adj[idx,:]>0)[0]\n",
    "\n",
    "        p1 = new_coord[idx,:]\n",
    "        p2 = new_coord[deg_2_neighbor[0],:]\n",
    "        p3 = new_coord[deg_2_neighbor[1],:]\n",
    "        l1 = p2-p1\n",
    "        l2 = p3-p1\n",
    "\n",
    "        node_angle = angle(l1,l2)*180 / math.pi\n",
    "\n",
    "        if node_angle>160:\n",
    "#             connecting_line = np.array(Bresenham3D(np.int32(p2*np.array(new_patch.shape)), np.int32(p3*np.array(new_patch.shape))))\n",
    "#             if (new_patch[connecting_line[:,0], connecting_line[:,1], connecting_line[:,2]]>0).all():\n",
    "            node_mask[idx]=False\n",
    "            new_dist_adj[deg_2_neighbor[0], deg_2_neighbor[1]] = np.sum((p2-p3)**2)\n",
    "            new_dist_adj[deg_2_neighbor[1], deg_2_neighbor[0]] = np.sum((p2-p3)**2)\n",
    "\n",
    "            new_dist_adj[idx, deg_2_neighbor[0]] = 0.0\n",
    "            new_dist_adj[deg_2_neighbor[0], idx] = 0.0\n",
    "            new_dist_adj[idx, deg_2_neighbor[1]] = 0.0\n",
    "            new_dist_adj[deg_2_neighbor[1], idx] = 0.0\n",
    "            break\n",
    "        elif n==len(deg_2)-1:\n",
    "            start = False\n",
    "\n",
    "new_coord = new_coord[node_mask,:]\n",
    "new_dist_adj = new_dist_adj[np.ix_(node_mask, node_mask)]\n",
    "new_edge = np.array(np.where(np.triu(new_dist_adj)>0)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3)\n"
     ]
    }
   ],
   "source": [
    "path = ('post2')\n",
    "save_output(path, 1, new_coord, new_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = [ 0.01931787, -0.0222708,  0.02970314] \n",
    "p2 = [-0.01931787,  0.02227092, -0.02970266]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179.99943856089104"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle(p1,p2)*180 / math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,9,3) (18,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-006780d10932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeg_2_neighbor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,9,3) (18,3) "
     ]
    }
   ],
   "source": [
    "# straighten the graph by removing redundant nodes\n",
    "degree = full_adj.sum(1)\n",
    "deg_2 = np.where(degree==2)\n",
    "deg_2_neighbor = np.where(full_adj[deg_2,:])\n",
    "p1 = coord[deg_2,:]\n",
    "p2 = coord[deg_2_neighbor[0],:]\n",
    "p3 = coord[deg_2_neighbor[1],:]\n",
    "\n",
    "l1 = p1-p3\n",
    "l2 = p2-p3\n",
    "\n",
    "node_angle = angle(l1,l2)*180 / math.pi\n",
    "\n",
    "remove_node = np.where(node_angle>170)\n",
    "while remove_node.sum()>0:\n",
    "    full_adj[deg_2[remove_node], deg_2[deg_2_neighbor[0][remove_node]]] = 0.0\n",
    "    full_adj[deg_2[deg_2_neighbor[0][remove_node]], deg_2[remove_node]] = 0.0\n",
    "    full_adj[deg_2[remove_node], deg_2[deg_2_neighbor[1][remove_node]]] = 0.0\n",
    "    full_adj[deg_2[deg_2_neighbor[1][remove_node]], deg_2[remove_node]] = 0.0\n",
    "    full_adj[deg_2[deg_2_neighbor[0][remove_node]], deg_2[deg_2_neighbor[1][remove_node]]] = 1.0\n",
    "    full_adj[deg_2[deg_2_neighbor[1][remove_node]], deg_2[deg_2_neighbor[0][remove_node]]] = 1.0\n",
    "\n",
    "    degree = full_adj.sum(1)\n",
    "    deg_2 = np.where(degree==2)\n",
    "    deg_2_neighbor = np.where(full_adj[deg_2,:])\n",
    "    p1 = coord[deg_2,:]\n",
    "    p2 = coord[deg_2_neighbor[0],:]\n",
    "    p3 = coord[deg_2_neighbor[1],:]\n",
    "\n",
    "    l1 = p1-p3\n",
    "    l2 = p2-p3\n",
    "\n",
    "    node_angle = angle(l1,l2)*180 / math.pi\n",
    "\n",
    "    remove_node = np.where(node_angle>170)\n",
    "\n",
    "new_nodes = np.where(degree>0)\n",
    "new_coord = coord[new_nodes,:]\n",
    "new_adj = full_adj[new_nodes, new_nodes]\n",
    "new_edge = np.where(np.triu(new_adj)>0)\n",
    "\n",
    "\n",
    "mod_patch_coord_list.append(new_coord)\n",
    "mod_patch_edge_list.append(new_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_edge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-95278b90c017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msave_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_patch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_edge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_edge' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,data in enumerate(dataset):\n",
    "# #     save_patch(data[0][1], data[1][1], data[2][1])\n",
    "#     print(i, data[0][1].shape, data[1][1].shape, data[2][1].shape)\n",
    "# #     save_patch(data[0][1], data[1][1], data[2][1])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_embedding = PositionalEncoding3D(channels=config.MODEL.DECODER.HIDDEN_DIM)\n",
    "query_embed = nn.Embedding(num_embeddings=100, embedding_dim=config.MODEL.DECODER.HIDDEN_DIM).weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "enocder = build_swin_transformer(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list, mask_list, pos_list = enocder(images.to(device), position_embedding, return_interm_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = build_detr_transformer(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2, 1024])\n",
      "torch.Size([100, 2, 1024])\n",
      "torch.Size([100, 2, 1024])\n",
      "torch.Size([100, 2, 1024])\n",
      "torch.Size([100, 2, 1024])\n",
      "torch.Size([100, 2, 1024])\n"
     ]
    }
   ],
   "source": [
    "out = decoder(feat_list[0].flatten(2).flatten(2).transpose(1, 2), None, query_embed, pos_list[0].transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 1024])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = decoder(out, tgt_graph, tgt_node, tgt_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = matcher(h, points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "monai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
